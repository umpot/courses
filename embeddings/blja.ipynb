{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "from keras import Input\n",
    "from keras.callbacks import Callback\n",
    "\n",
    "from keras.datasets import imdb\n",
    "from keras.layers import Embedding, Dense, Flatten, Dropout, SpatialDropout1D, Convolution1D, MaxPooling1D\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import Adam\n",
    "from keras.preprocessing import sequence\n",
    "from keras.utils import get_file\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import os\n",
    "import bcolz\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_fp = '../../../data/glove/glove.6B/glove.6B.50d.txt'\n",
    "def load_glove(fp):\n",
    "    with open(fp) as f:\n",
    "        ll = f.readlines()\n",
    "        ll = [x.split() for x in ll]\n",
    "        words = [x[0] for x in ll]\n",
    "        vecs = [x[1:] for x in ll]\n",
    "        vecs = [[float(y) for y in x] for x in vecs]\n",
    "        return {words[i]: vecs[i] for i in range(len(words))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sum_emb_input(words_arr, emb_dict):\n",
    "    res = []\n",
    "    for x in words_arr:\n",
    "        res_inner = []\n",
    "        for y in x:\n",
    "            try:\n",
    "                res_inner.append(emb_dict[y])\n",
    "            except:\n",
    "                print y\n",
    "\n",
    "        res_inner = np.mean(res_inner, axis=0)\n",
    "        res.append(res_inner)\n",
    "\n",
    "    return res\n",
    "\n",
    "def get_merge_emb_input(words_arr, emb_dict, max_num):\n",
    "    res = []\n",
    "    for x in words_arr:\n",
    "        res_inner = []\n",
    "        for y in x:\n",
    "            try:\n",
    "                res_inner+=emb_dict[y]\n",
    "            except:\n",
    "                print y\n",
    "        if len(res_inner)>=max_num:\n",
    "            res.append(res_inner[:max_num])\n",
    "        else:\n",
    "            delta = max_num-len(res_inner)\n",
    "            res_inner=res_inner+[0]*delta\n",
    "            res.append(res_inner)\n",
    "\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle_input(x,y):\n",
    "    z = zip(x,y)\n",
    "    z = np.random.permutation(z)\n",
    "\n",
    "    return np.array([m[0] for m in z]), np.array([m[1] for m in z])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_to_index = imdb.get_word_index()\n",
    "\n",
    "index_to_word = {v: k for k, v in word_to_index.iteritems()}\n",
    "\n",
    "path = get_file('imdb_full.pkl',\n",
    "                origin='https://s3.amazonaws.com/text-datasets/imdb_full.pkl',\n",
    "                md5_hash='d091312047c43cf9e4e38fef92437263')\n",
    "f = open(path, 'rb')\n",
    "(x_train, labels_train), (x_test, labels_test) = pickle.load(f)\n",
    "x_train_words = [[index_to_word[y] for y in x] for x in x_train]\n",
    "x_test_words = [[index_to_word[y] for y in x] for x in x_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_glove = load_glove(glove_fp)\n",
    "embeding_dim=50\n",
    "\n",
    "train_inp = get_merge_emb_input(x_train_words, d_glove, embeding_dim*50)\n",
    "test_inp = get_merge_emb_input(x_test_words, d_glove, embeding_dim*50)\n",
    "\n",
    "train_inp = np.array(train_inp)\n",
    "test_inp = np.array(test_inp)\n",
    "\n",
    "train_inp, labels_train = shuffle_input(train_inp, labels_train)\n",
    "test_inp, labels_test = shuffle_input(test_inp, labels_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Dense(50, activation='relu', input_shape=(embeding_dim*50,)),\n",
    "    Dense(1, activation='softmax', input_shape=(50,))\n",
    "])\n",
    "model.compile(optimizer=Adam(1e-6), loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(train_inp, labels_train, validation_data=(test_inp, labels_test), epochs=1, batch_size=64)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
